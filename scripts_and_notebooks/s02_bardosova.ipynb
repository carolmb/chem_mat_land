{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "!pip install ujson\n",
    "!pip install xnetwork\n",
    "!pip install infomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from os.path import join as PJ\n",
    "# import bgzf\n",
    "import struct\n",
    "import numpy as np\n",
    "import operator\n",
    "import gensim\n",
    "import ujson\n",
    "import igraph as ig\n",
    "import xnetwork as xn\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from os.path import join as PJ\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infomap import Infomap\n",
    "def infomapMembership(vertexCount,edges):\n",
    "    im = Infomap(\"-N 10 --ftree --silent --seed %d\"%np.random.randint(4294967296));\n",
    "    im.setVerbosity(0);\n",
    "    for nodeIndex in range(0,vertexCount):\n",
    "        im.add_node(nodeIndex)\n",
    "    for edge in edges:\n",
    "        im.add_link(edge[0], edge[1]);\n",
    "    im.run()\n",
    "    # print(\"Result\")\n",
    "    # print(\"\\n#node module\")\n",
    "    membership = [0]*vertexCount;\n",
    "    for node in im.tree:\n",
    "        if node.is_leaf:\n",
    "            membership[node.node_id] = node.module_id;\n",
    "    return membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infomapApply(g, weights=None):\n",
    "    vertexCount = g.vcount()\n",
    "    if(weights):\n",
    "        edges = [(e.source, e.target, e[weights]) for e in g.es]\n",
    "    else:\n",
    "        edges = g.get_edgelist()\n",
    "\n",
    "#     if(g.is_directed()):\n",
    "#         extraOptions = \"-d\"\n",
    "#     else:\n",
    "    extraOptions = \"\"\n",
    "    im = Infomap(\"%s -N 10 --silent --seed %d\" %\n",
    "                 (extraOptions, np.random.randint(4294967296)))\n",
    "    \n",
    "    im.setVerbosity(0)\n",
    "    for nodeIndex in range(0, vertexCount):\n",
    "        im.add_node(nodeIndex)\n",
    "    for edge in edges:\n",
    "        if(len(edge) > 2):\n",
    "            if(edge[2]>0):\n",
    "                im.addLink(edge[0], edge[1], edge[2])\n",
    "            im.add_link(edge[0], edge[1], weight=edge[2])\n",
    "        else:\n",
    "            im.add_link(edge[0], edge[1])\n",
    "\n",
    "    im.run()\n",
    "    membership = [\":\".join([str(a) for a in membership])\n",
    "                  for index, membership in im.get_multilevel_modules().items()]\n",
    "\n",
    "    levelMembership = []\n",
    "    levelCount = max([len(element.split(\":\")) for element in membership])\n",
    "    for level in range(levelCount):\n",
    "        print(level)\n",
    "        levelMembership.append(\n",
    "            [\":\".join(element.split(\":\")[:(level+1)]) for element in membership]\n",
    "        )\n",
    "    return levelMembership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading manual dictionary an ignore list.\n",
      "Setting up nltk environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/acmbrito/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/acmbrito/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords;\n",
    "from nltk.stem.wordnet import WordNetLemmatizer;\n",
    "import nltk.data;\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, sent_tokenize;\n",
    "from nltk.corpus import wordnet;\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "verboseMode = True;\n",
    "\n",
    "# Loading manual dictionary an ignore list\n",
    "if(verboseMode): print(\"Loading manual dictionary an ignore list.\");\n",
    "replaceDictionary = {};\n",
    "# with open(\"replaceDictionary.dat\",\"r\") as fp:\n",
    "# \tfor line in fp:\n",
    "# \t\tentry = line.strip().split(\"\\t\");\n",
    "# \t\tif(len(entry)>1):\n",
    "# \t\t\treplaceDictionary[entry[0]] = entry[1];\n",
    "\n",
    "# ignoreSet = set();\n",
    "# with open(\"ignoreSet.dat\",\"r\") as fp:\n",
    "# \tfor line in fp:\n",
    "# \t\tignoreSet.add(line.strip());\n",
    "\n",
    "\n",
    "#Setting up nltk environment\n",
    "if(verboseMode): print(\"Setting up nltk environment.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/acmbrito/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/acmbrito/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'off', 'before', 'do', 'each', \"hadn't\", 'hasn', 'their', 'his', 'we', \"that'll\", 'over', \"it's\", 'doing', 'very', 'did', 'few', 'during', 'these', 'too', \"you'll\", 'will', 'haven', 'mightn', 'as', 'having', \"aren't\", 'up', 'd', 'your', 'but', 'does', \"haven't\", 'then', 'll', 'wouldn', 'herself', 'yourself', 'are', 'from', 'now', \"weren't\", 'has', \"doesn't\", 'all', \"you're\", 'more', 'm', 'nor', 'ourselves', \"wasn't\", 've', 'been', 'yourselves', \"didn't\", 'he', 'which', 'or', 'while', 'here', 'how', 'just', 'below', 'me', 's', 'o', 'ma', \"hasn't\", 'only', 'an', 'through', 'those', 'she', 'theirs', 'into', 'yours', 'against', 'after', 'myself', 'so', 'should', 'for', 'you', 'under', \"she's\", 'at', 'when', 'in', 'why', 'if', 'isn', 'and', 'same', 'shan', \"needn't\", 'don', 'can', 'they', 'who', 'again', 'own', 'aren', 'on', 'have', \"wouldn't\", 'our', 'it', 'ours', 'didn', 'with', 'her', \"shouldn't\", 'a', \"won't\", 'of', 'this', \"mustn't\", 'himself', 'won', 'had', 'some', 'above', 'both', 't', 'my', 'that', 'until', 'what', 'to', 'the', \"you've\", 'any', 'whom', 'them', 'by', \"couldn't\", 'no', 'him', 'than', 'mustn', 'were', 'down', 'there', \"isn't\", 'shouldn', 'such', 'itself', \"don't\", 'out', 'themselves', 'once', 'am', \"should've\", 'is', 'further', 'be', 'being', 'i', 'y', 'hers', 'most', 'its', 'other', 'needn', 're', 'weren', 'where', 'was', 'couldn', 'hadn', 'not', 'between', 'ain', \"you'd\", \"mightn't\", 'because', \"shan't\", 'about', 'wasn', 'doesn'}\n",
      "Loading manual dictionary an ignore list.\n",
      "Setting up nltk environment.\n",
      "Setting up tokenizer.\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "from nltk.corpus import stopwords;\n",
    "from nltk.stem.wordnet import WordNetLemmatizer;\n",
    "import nltk.data;\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, sent_tokenize;\n",
    "from nltk.corpus import wordnet;\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "lmtzr = WordNetLemmatizer();\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "punctuation = re.compile(r'[(\\])(\\})(\\{)(\\[).?!,\":;()|]');\n",
    "stopSet = set(stopwords.words('english'));\n",
    "\n",
    "print(stopSet)\n",
    "\n",
    "verboseMode = True;\n",
    "\n",
    "# Loading manual dictionary an ignore list\n",
    "if(verboseMode): print(\"Loading manual dictionary an ignore list.\");\n",
    "replaceDictionary = {};\n",
    "with open(\"replaceDictionary.txt\",\"r\") as fp:\n",
    "\tfor line in fp:\n",
    "\t\tentry = line.strip().split(\"\\t\");\n",
    "\t\tif(len(entry)>1):\n",
    "\t\t\treplaceDictionary[entry[0]] = entry[1];\n",
    "\n",
    "ignoreSet = set();\n",
    "with open(\"ignoreSet.txt\",\"r\") as fp:\n",
    "\tfor line in fp:\n",
    "\t\tignoreSet.add(line.strip());\n",
    "\n",
    "\n",
    "#Setting up nltk environment\n",
    "if(verboseMode): print(\"Setting up nltk environment.\");\n",
    "\n",
    "\n",
    "def findWholeWord(w):\n",
    "\treturn re.compile(r'\\b({0})\\b'.format(w), flags=re.IGNORECASE).search\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\tif treebank_tag.startswith('J'):\n",
    "\t\treturn wordnet.ADJ\n",
    "\telif treebank_tag.startswith('V'):\n",
    "\t\treturn wordnet.VERB\n",
    "\telif treebank_tag.startswith('N'):\n",
    "\t\treturn wordnet.NOUN\n",
    "\telif treebank_tag.startswith('R'):\n",
    "\t\treturn wordnet.ADV\n",
    "\telse:\n",
    "\t\treturn ''\n",
    "\n",
    "# def get_wordnet_pos(treebank_tag):\n",
    "# \tif treebank_tag.startswith('J'):\n",
    "# \t\treturn -1\n",
    "# \telif treebank_tag.startswith('V'):\n",
    "# \t\treturn -1\n",
    "# \telif treebank_tag.startswith('N'):\n",
    "# \t\treturn wordnet.NOUN\n",
    "# \telif treebank_tag.startswith('R'):\n",
    "# \t\treturn wordnet.ADV\n",
    "# \telse:\n",
    "# \t\treturn ''\n",
    "\n",
    "#Setting up tokenizer\n",
    "if(verboseMode): print(\"Setting up tokenizer.\");\n",
    "\n",
    "tokenizerInput = {\n",
    "\t\"stopSet\":stopSet,\n",
    "\t\"punctuation\":punctuation,\n",
    "\t\"tokenizer\":sent_tokenizer,\n",
    "\t\"lematizer\":lmtzr,\n",
    "\t\"sent_tokenize\": sent_tokenize,\n",
    "\t\"replaceDictionary\": replaceDictionary,\n",
    "\t\"ignoreSet\":ignoreSet\n",
    "}\n",
    "\n",
    "def tokenizeString(theString,maximumTokenSize,tokenizerInput,removeStopWords=True):\n",
    "\tstopSet = tokenizerInput[\"stopSet\"];\n",
    "\tlematizer = tokenizerInput[\"lematizer\"];\n",
    "\ttokenizer = tokenizerInput[\"tokenizer\"];\n",
    "\tpunctuation = tokenizerInput[\"punctuation\"];\n",
    "\tsent_tokenize = tokenizerInput[\"sent_tokenize\"];\n",
    "\treplaceDictionary = tokenizerInput[\"replaceDictionary\"];\n",
    "\tignoreSet = tokenizerInput[\"ignoreSet\"];\n",
    "\twordsList = [];\n",
    "\ttitleAbstract = (\". \".join(theString.split(\"::\"))).strip();\n",
    "\twordsSentences = [word_tokenize(t) for t in sent_tokenize(titleAbstract)];\n",
    "\tstopSentence = False;\n",
    "\tfor si, words in enumerate(wordsSentences):\n",
    "\t\twordsTags = nltk.pos_tag(words);\n",
    "\t\tif(stopSentence):\n",
    "\t\t\tbreak;\n",
    "\t\tfor wi,wordTag in enumerate(wordsTags):\n",
    "\t\t\tword = wordTag[0];\n",
    "\t\t\ttag = wordTag[1];\n",
    "\t\t\t\n",
    "\t\t\tif word.isdigit() or word[1:].isdigit():\n",
    "\t\t\t\tcontinue;\n",
    "# \t\t\tif(si>len(wordsSentences)-4 and (word.lower()==\"copyright\" or (wi>0 and word.lower()==\"c\" and words[wi-1] == \"(\"  and words[wi+1] == \")\" ))):\n",
    "# \t\t\t\tstopSentence = True;\n",
    "# \t\t\t\tbreak;\n",
    "\t\t\tword = punctuation.sub(\"\", word);\n",
    "\t\t\tconvTag = get_wordnet_pos(tag);\n",
    "\t\t\t#print \"w: \"+word;\n",
    "\t\t\tif convTag == -1:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif(convTag != ''):\n",
    "\t\t\t\tword  = lematizer.lemmatize(word.lower(), convTag);\n",
    "\t\t\telse:\n",
    "\t\t\t\tword  = lematizer.lemmatize(word.lower());\n",
    "\t\t\tif(len(word)==0 or ((word in stopSet) and removeStopWords) or (word in ignoreSet)):\n",
    "\t\t\t\tcontinue;\n",
    "\t\t\telse:\n",
    "\t\t\t\tif(word in replaceDictionary):\n",
    "\t\t\t\t\twordsList.append(replaceDictionary[word]);\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\twordsList.append(word);\n",
    "\n",
    "\ttokens = [set() for i in range(maximumTokenSize)];\n",
    "\tfor wordIndex in range(len(wordsList)):\n",
    "\t\tfor tokenSize in range(0,min(wordIndex+1,maximumTokenSize)):\n",
    "\t\t\ttokens[tokenSize].add(\" \".join(wordsList[(wordIndex-tokenSize):(wordIndex+1)]));\n",
    "\treturn tokens;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cit_net_windows/citing_net_chem. mat._time_windows_1988_1992_2023-05-30.xnet', 'cit_net_windows/citing_net_chem. mat._time_windows_1993_1997_2023-05-30.xnet', 'cit_net_windows/citing_net_chem. mat._time_windows_1998_2002_2023-05-30.xnet', 'cit_net_windows/citing_net_chem. mat._time_windows_2003_2007_2023-05-30.xnet', 'cit_net_windows/citing_net_chem. mat._time_windows_2008_2012_2023-05-30.xnet', 'cit_net_windows/citing_net_chem. mat._time_windows_2013_2017_2023-05-30.xnet', 'cit_net_windows/citing_net_chem. mat._time_windows_2018_2022_2023-05-30.xnet']\n"
     ]
    }
   ],
   "source": [
    "# files = ['citing_net_chem. mat._journals_2023-05-25.xnet']\n",
    "files = glob.glob('cit_net_windows/*.xnet')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining the major connected component.\n",
      "Tokenizing the abstracts.\n",
      "Done                         \n",
      "Obtaining the network community structure.\n",
      "0\n",
      "1\n",
      "\n",
      "Getting tokens frequency.\n",
      "Calculating the importance Index.\n",
      "A - ammonia, pyrolysis, silicon, silicon-carbide, gallium nitride, poly carbosilane, chemistry, using, atmospheric-pressure chemical vapor-deposition...\n",
      "B - chemical vapor-deposition copper, complex, compound, deposition copper, vapor-deposition copper copper, amorphous, boride, chemical vapor-deposit...\n",
      "C - ceramic, coating, precursor boron-nitride, preparation, boron, polymer, polymeric precursor, synthesis, formation, powder\n",
      "D - \n",
      "Saving the network.\n",
      "Obtaining the major connected component.\n",
      "Tokenizing the abstracts.\n",
      "Done                            \n",
      "Obtaining the network community structure.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "\n",
      "Getting tokens frequency.\n",
      "Calculating the importance Index.\n",
      "A - mesoporous, structure, vanadium, phosphate, hydrothermal synthesis, h2o, surfactant, molecular sieve, silica, vo\n",
      "B - nanocomposites, layered, pillared, intercalation, clay, layer, compound, phosphate, metal, preparation\n",
      "C - composite, silica, sol-gel material, optical, sol-gel synthesis, hybrid organic-inorganic, matrix, glass, process, fluorescence\n",
      "D - nitride, ceramic, conversion, deposition, silicon, synthesis, polymeric precursor, chemical-vapor-deposition, gallium, pyrolysis\n",
      "E - poly, conductivity, coupling, thiophene oligomers, polythiophene derivative, conduct polymer, anodic, polyaniline, copolymer, polymerization\n",
      "F - chromophore, polymer, second-order, 2nd-order nonlinear-optical, nonlinear optical, effect, nonlinear optic, generation, nonlinear-optical materi...\n",
      "G - nanoclusters, nanoparticles, formation, surface, silver, matrix, precursor, particle, polyimide film, bimetallic\n",
      "H - manganese oxide, precursor, film, spinel, deposition, growth, octahedral, sol-gel, reaction, characterization\n",
      "I - zirconium, self-assembled, monolayer, patterned, compound, organic, crystal, acid, layered, phosphonates\n",
      "J - structure, novel, sulfide, framework, center dot, hydrothermal synthesis, crystal, situ sol-gel, synchrotron, plate\n",
      "K - metallomesogens, chemically amplified, resists, poly, complex, transition-metals, lithographic, resist, mesophases, methacrylate\n",
      "L - ultrafine, template, nanoscale, oxide, adsorption, carbon, particle, chemical reagent, chlorinated, hydrocarbon\n",
      "M - perovskites, one-dimensional, ion, phase, electrosynthesis, conductor, synthesis layered, perovskite oxide, oxygen-deficient, anion-deficient\n",
      "N - \n",
      "Saving the network.\n",
      "Obtaining the major connected component.\n",
      "Tokenizing the abstracts.\n",
      "Done                              \n",
      "Obtaining the network community structure.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "\n",
      "Getting tokens frequency.\n",
      "Calculating the importance Index.\n",
      "A - mesoporous silica, mesostructured, molecular sieve, characterization, porous, synthesis, sba-15, hexagonal, mcm-41, nanoporous\n",
      "B - layered, perovskite, nanocomposite, layer, film, silicate nanocomposites, intercalation, layer-by-layer, montmorillonite, preparation\n",
      "C - template, nanowires, macroporous, colloidal, nanotube, hollow, fabrication, particle, nanoparticles, sphere\n",
      "D - structure, center dot, phosphate, templated, hydrothermal synthesis, h2o, three-dimensional, characterization, hpo4, po4\n",
      "E - sol-gel process, complex, silica, organically modify, hybrid material, luminescence, sol-gel-derived, xerogels, organic-inorganic, modify silicate\n",
      "F - nanoparticles, catalyst, characterization, preparation, synthesis, particle, gold, film, oxide, surface\n",
      "G - poly, polymer, electrochromic, electrochemical, semiconductor, thiophene, oligomers, monomer, optical, conjugate\n",
      "H - chromophore, nonlinear optic, toward, n, magnetic, structure, ii, second-order nonlinear optical, high, nickel\n",
      "I - manganese oxide, spinel, nmr, material, lithium, birnessite, si-b-c-n ceramic precursor, pillared, framework, hybrid\n",
      "J - polymer, electroluminescent, device, transport, novel, hole, organic light-emitting diode, emit, light-emitting diode base, material\n",
      "K - oh, layered double hydroxide, hydrotalcite-like compound, layer double hydroxide, no3, center dot, anion, intercalation, formation, route\n",
      "L - magnetic, oxide, electrochemical, fe, po4, nanocrystalline, nabi3v2o10, conductor, gamma-fe2o3, nanoparticles\n",
      "M - block copolymer, cd, nanoparticles, preparation, nanospheres, semiconductor, electronic, copper, poly, growth\n",
      "N - gallium nitride, synthesis, nanocrystalline, solvothermal, gan, route, growth, control, via, precursor\n",
      "O - nanotube, optical, vanadium oxide, chfcf2, r ch2cf2, beta et sf5rso3, electronic, chemical, v2o5, synthesis vanadium\n",
      "P - dendrimers, poly, thin film, silicon-containing, alpha-titanium, methylsilsesquioxane derivative, dendrimer-based xerogels, laser, dendrimer, mor...\n",
      "Q - titania, hydrothermal, film, sol-gel, anatase, dioxide, tin, amorphous, system, titanium\n",
      "R - chromophore, dye, perylene, two-photon, two-photon-absorbing, acceptor, design, layer-by-layer, self-assembly, base\n",
      "S - oxide, commensurate, crystal magnetic structure, n=3 ruddlesden-popper phase, prismatic, monodimensional, structural chemistry, orthorhombic, fam...\n",
      "T - \n",
      "Saving the network.\n",
      "Obtaining the major connected component.\n",
      "Tokenizing the abstracts.\n",
      "Done                              \n",
      "Obtaining the network community structure.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "\n",
      "Getting tokens frequency.\n",
      "Calculating the importance Index.\n",
      "A - mesoporous, silica, nanoparticles, film, carbon, organic, synthesis, polymer, gold, deposition\n",
      "B - lithium, electrochemical, battery, structure, li, structural, electrode, oxide, x, phase\n",
      "C - \n",
      "Saving the network.\n",
      "Obtaining the major connected component.\n",
      "Tokenizing the abstracts.\n",
      "Done                              \n",
      "Obtaining the network community structure.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "\n",
      "Getting tokens frequency.\n",
      "Calculating the importance Index.\n",
      "A - organic, transistor, polymer, solar cell, base, efficient, photovoltaic, device, semiconductor, field-effect\n",
      "B - lithium, electrode, cathode, material, lithium-ion battery, structure, electrochemical, li-ion battery, lifepo4, olivine\n",
      "C - oxygen, structure, perovskite, oxide, structural, perovskites, solid, conductivity, magnetic, fuel\n",
      "D - mesoporous silica, porous, hierarchical, titania, thin film, synthesis, ordered mesoporous, hierarchically, templating, sol-gel\n",
      "E - nanoparticles, silica, capsule, fabrication, via, imaging, fluorescent, hollow, assembly, shell\n",
      "F - nanocrystals, synthesis, quantum dot, tio2 nanotube, sulfide, semiconductor, precursor, control, cuins2, cdse\n",
      "G - nanoparticles, battery, synthesis, core-shell, metal, lithium storage, nanowires, nickel, ni, anode\n",
      "H - atomic layer deposition, thin film, growth, reaction, oxide, precursor, vapor, ozone, substrate, using\n",
      "I - porous, polymer, mesoporous carbon, aerogels, nanoporous, microporous, framework, hydrogen storage, organic, network\n",
      "J - water, alpha-fe2o3, photoelectrochemical, structure, transparent, structural, evolution, spectroscopy, complex, garnet\n",
      "K - structure, thermal, pbte, thermoelectric material, sb, compound, physical, crystal, zintl, te\n",
      "L - magnetic, nanoparticles, calcium phosphate, drug, diamond, bone, iron oxide, system, nanocomposites, ferrite\n",
      "M - synthesis, nanoparticles, germanium, growth, gold, transition-metal nanocluster, agent, dispersive kinetic, kinetic data, intermetallic\n",
      "N - supercapacitor, layered double hydroxide, graphene oxide, nanowires, electrode, mesoporous carbon, cobalt, core-shell, poly, nanofibrous\n",
      "O - graphene, nanoparticles, pt, platinum, au, synthesis, alloy, membrane, characterization, preparation\n",
      "P - tio2, anatase, water, alkoxide cluster, mgo nanoparticles variable, organometallic precursor, zinc oxide, light, photocatalytic, mesoporous\n",
      "Q - nanowires, germanium, high, chemistry, graphene, nanowire, growth, film, fabrication, silica\n",
      "R - synthesis, metal-organic framework, porous, zeolitic imidazolate framework, coordination polymer, center dot, oh, hydroxide, membrane, control\n",
      "S - zeolite, mesoporous, hierarchical, silica, assembly, nanotube, hollow, molecular, porous, carbon\n",
      "T - mesoporous silica, material, nanospheres, molecular-scale, organic-inorganic hybrid, organosilica, sba-15, mesostructured, self-assembled, surface\n",
      "U - ionic liquid, proton, membrane, layered, imidazolium, anion, exchange, hydroxide, conductivity, hybrid\n",
      "W - \n",
      "Saving the network.\n",
      "Obtaining the major connected component.\n",
      "Tokenizing the abstracts.\n",
      "Done                              \n",
      "Obtaining the network community structure.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "\n",
      "Getting tokens frequency.\n",
      "Calculating the importance Index.\n",
      "A - nanocrystals, synthesis, colloidal, nanoparticles, quantum dot, growth, nanocrystal, exchange, surface, control\n",
      "B - battery, cathode material, electrochemical, electrode, li, lithium, ion, layered, na-ion, li-ion\n",
      "C - organic solar cell, transistor, photovoltaic, copolymer, acceptor, polymer solar cell, molecular, effect, conjugated polymer, high-performance\n",
      "D - metal-organic framework, porous, adsorption, co2, gas, covalent organic framework, separation, metal organic framework, carbon, proton\n",
      "E - perovskites, perovskite solar cell, halide perovskite, hybrid, methylammonium lead, lead iodide, ch3nh3pbi3, film, lead-free, perovskite nanocrys...\n",
      "F - phosphor, eu2+, luminescence, solid electrolyte, solid-state, structure, superionic conductor, li7la3zr2o12, garnet, narrow-band\n",
      "G - high-throughput, design, compound, nitride, material, oxide, machine learning, snse, prediction, analysis\n",
      "H - zeolite, synthesis, agent, structure, crystallization, precursor, organic, layered, aluminum, molecular\n",
      "I - atomic layer deposition, hydrogel, chemistry, thin film, metal, gold, polydopamine, network, electrolyte, precursor\n",
      "J - oxynitride, silicon nanocrystals, anion, film, thermal expansion, research, block copolymer, zeolite, structural, self-assembly\n",
      "K - supramolecular, mesoporous silica nanoparticles, drug release, drug delivery, raman, ultrasmall, block copolymer, enhanced, assembly, protein\n",
      "L - response, second harmonic generation, layered, nonlinear optical material, infrared, se, k, large, semiconductor, selective\n",
      "M - aerogels, porous, monolith, mesoporous, flexible, highly, ordered, aerogel, hierarchically, template\n",
      "N - compound, thermal conductivity, phase, high thermoelectric, x <, structure, doping, tetrahedrites, cosb3, zintl\n",
      "O - exfoliation, mos2, nanosheets, mxene, layered, two-dimensional titanium carbide, hydrogen evolution reaction, titanium, liquid, molybdenum\n",
      "P - graphene oxide, composite, preparation, graphite, ordered mesoporous, toward, mesoporous carbon, supercapacitors, enhanced, membrane\n",
      "Q - organic light-emitting diode, thermally activated delayed, blue, activated delayed fluorescence, emitter, efficiency, efficient, host, emission, ...\n",
      "R - atomic layer deposition, metal-organic framework, battery, lithium, molecular, metal, stabilization, solid electrolyte, film, interface\n",
      "S - atomic layer deposition, atomic layer etching, precursor, using sequential, thermal, film, reaction, al2o3, layer-by-layer, graphene\n",
      "T - synthesis, growth, plasmonic, gold nanorod, gold nanorods, au, nanoparticles, control, agent, nanostructures\n",
      "U - high thermoelectric, x, thermoelectric material, band, compound, lattice thermal conductivity, low thermal conductivity, low lattice thermal, cer...\n",
      "W - graphene, growth, chemical vapor deposition, copper, film, hexagonal boron nitride, anode, monolayer, metal, using\n",
      "V - germanium, situ, sodium-ion battery, anode lithium-ion, via, lithium ion battery, system, spectroscopy, lithium-ion battery, x-ray\n",
      "X - early, chemistry material 1k, material 1k club, up-and-coming series perspective, editor, peer, mesoporous material, rise, paper, nanomaterials\n",
      "Y - \n",
      "Saving the network.\n",
      "Obtaining the major connected component.\n",
      "Tokenizing the abstracts.\n",
      "Done                              \n",
      "Obtaining the network community structure.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "\n",
      "Getting tokens frequency.\n",
      "Calculating the importance Index.\n",
      "A - perovskites, lead, hybrid, phosphor, perovskite nanocrystals, emission, halide perovskite, luminescence, x, br\n",
      "B - nanocrystals, quantum dot, colloidal, nanoplatelets, synthesis, ligand, cdse, nanoparticles, cation exchange, chalcogenide\n",
      "C - battery, lithium, ion, solid electrolyte, conductor, conductivity, superionic, conduction, all-solid-state, diffusion\n",
      "D - acceptor, transistor, high-performance, organic solar cell, electron, semiconducting polymer, all-polymer, conjugated polymer, efficient, semicon...\n",
      "E - machine learning, material, prediction, discovery, design, membrane, separation, polymer, screening, high-throughput\n",
      "F - atomic layer deposition, precursor, area-selective atomic layer, using, thin film, oxide, atomic layer etching, thermal atomic layer, chemical va...\n",
      "G - nonlinear optical material, polar, large, generation response, strong, second harmonic generation, second-harmonic generation, infrared nonlinear...\n",
      "H - redox, cathode material, li-rich, disordered, lithium-ion battery, surface, rocksalt, layered oxide cathode, ni-rich, li\n",
      "I - plasmonic, thin, electrochromic, continuous growth synthesis, indium oxide nanocrystals, colloidal, metal oxide, influence, nanocrystal, film\n",
      "J - synthesis, thermoelectric, electronic, neutron diffraction, layered oxide, design, situ, structural, li, anion\n",
      "K - boron nitride nanotube, chemical warfare agent, impact, synthesis, framework, nitride nanotube via, purification boron nitride, microfluidic, chr...\n",
      "L - palladium, film, spectroscopy, crystal, melanin, virtual issue protocol, hydrogen absorption, bise, mose2, heterostructure\n",
      "M - organic, microspacing in-air sublimation, in-air sublimation growth, stiff, self-healable, pandemic, ti3c2tx, anisotropic growth, rate, cause\n",
      "N - bivo4, water splitting, oxygen, electrocatalysts, photoelectrochemical, hydrogen evolution, evolution reaction, activity, film, doping\n",
      "O - covalent organic framework, metal-organic, molecular engineering, ultrathin two-dimensional, injection, lithium-sulfur battery, porous, selectivi...\n",
      "P - \n",
      "Saving the network.\n"
     ]
    }
   ],
   "source": [
    "# Some util functions\n",
    "dateoutput = '180423'\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    jsonFileprefix = file[:-5] + '_bardo'\n",
    "    removeStopWords = True;\n",
    "    maximumTokenSize = 3; #n-gram\n",
    "    minKeywordsPerCluster = 10;\n",
    "    maxKeywordsPerCluster = 10;\n",
    "    maxClusterNameLength = 150;\n",
    "    useMajorComponent = True;\n",
    "    verboseMode = True;\n",
    "\n",
    "    network = xn.xnet2igraph(file)\n",
    "    network.vs['wos_id'] = network.vs['name']\n",
    "    network.vs['name'] = network.vs['title']\n",
    "    \n",
    "    \n",
    "    # Obtaining the major connected component (if needed)\n",
    "    if(useMajorComponent):\n",
    "        if(verboseMode): print(\"Obtaining the major connected component.\");\n",
    "        network = network.clusters(\"WEAK\").giant();\n",
    "\n",
    "    # Tokenizing the abstracts\n",
    "    if(verboseMode): print(\"Tokenizing the abstracts.\");\n",
    "    tokensFrequency = [[] for i in range(maximumTokenSize)];\n",
    "    tokensGroupFrequency = [{} for i in range(maximumTokenSize)];\n",
    "\n",
    "    propertiesKeys = set();\n",
    "\n",
    "    verticesTokens = [];\n",
    "    for vertexIndex in range(network.vcount()):\n",
    "        if(vertexIndex%100==0):\n",
    "            print(\"Tokenizing: %d/%d             \"%(vertexIndex,network.vcount()),end=\"\\r\")\n",
    "\n",
    "    #         for wordsList in tokenList:\n",
    "    #             tokens = [set() for i in range(maximumTokenSize)];\n",
    "    #             for wordIndex in range(len(wordsList)):\n",
    "    #                 for tokenSize in range(0,min(wordIndex+1,maximumTokenSize)):\n",
    "    #                     tokens[tokenSize].add(\" \".join(wordsList[(wordIndex-tokenSize):(wordIndex+1)]));\n",
    "        verticesTokens.append(tokenizeString(network.vs[vertexIndex][\"title\"],maximumTokenSize,tokenizerInput));\n",
    "\n",
    "    print(\"Done                   \");\n",
    "\n",
    "    # Obtaining the network community structure\n",
    "    if(verboseMode): print(\"Obtaining the network community structure.\");\n",
    "    \n",
    "\n",
    "    edgelist = [(e.source,e.target) for e in network.es]\n",
    "    communities = infomapApply(network)[0]\n",
    "    communities = [int(c) for c in communities]\n",
    "    print()\n",
    "    \n",
    "    # print(\"Modularity: %f\"%cc.q);\n",
    "\n",
    "    clusters = [[] for i in range(max(communities)+1)];\n",
    "    for vertexIndex in range(network.vcount()):\n",
    "        clusters[communities[vertexIndex]].append(vertexIndex);\n",
    "\n",
    "    #sorting the clusters by size\n",
    "    clusters = sorted(clusters,key=len,reverse=True);\n",
    "\n",
    "    # Getting tokens frequency\n",
    "    if(verboseMode): print(\"Getting tokens frequency.\");\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tokenFrequencyInClusters = [];\n",
    "    tokenFrequencyInCorpus = {};\n",
    "\n",
    "    for clusterIndex in range(len(clusters)):\n",
    "        cluster = clusters[clusterIndex];\n",
    "        tokenFrequencyInCluster = {};\n",
    "        for vertexIndex in cluster:\n",
    "            tokens = verticesTokens[vertexIndex];\n",
    "            for tokenSize in range(0,maximumTokenSize):\n",
    "                for token in tokens[tokenSize]:\n",
    "                    if(token not in tokenFrequencyInCorpus):\n",
    "                        tokenFrequencyInCorpus[token] = 0;\n",
    "                    if(token not in tokenFrequencyInCluster):\n",
    "                        tokenFrequencyInCluster[token] = 0;\n",
    "                    tokenFrequencyInCorpus[token] += 1;\n",
    "                    tokenFrequencyInCluster[token] += 1;\n",
    "        tokenFrequencyInClusters.append(tokenFrequencyInCluster);\n",
    "\n",
    "    # Calculating the importance Index\n",
    "    if(verboseMode): print(\"Calculating the importance Index.\");\n",
    "    #tokenRelativeFrequencyInClusters = [];\n",
    "    #tokenRelativeFrequencyOutClusters = [];\n",
    "    tokenImportanceIndexInClusters = [];\n",
    "\n",
    "    verticesCount = network.vcount();\n",
    "    for clusterIndex in range(len(clusters)):\n",
    "        clusterSize = len(clusters[clusterIndex]);\n",
    "\n",
    "        tokenFrequencyInCluster = tokenFrequencyInClusters[clusterIndex];\n",
    "\n",
    "        #tokenRelativeFrequencyInCluster = {};\n",
    "        #tokenRelativeFrequencyOutCluster = {};\n",
    "        tokenImportanceIndexInCluster = {};\n",
    "\n",
    "        for token in tokenFrequencyInCluster:\n",
    "            nInCluster = tokenFrequencyInCluster[token];\n",
    "            nOutCluster = tokenFrequencyInCorpus[token]-nInCluster;\n",
    "            outClusterSize = verticesCount-clusterSize;\n",
    "            if(nOutCluster==0):\n",
    "                outClusterSize = 1; #Fix for singletons\n",
    "            FInCluster = float(nInCluster)/float(clusterSize);\n",
    "            FOutCluster = float(nOutCluster)/float(outClusterSize);\n",
    "            importanceIndex = FInCluster-FOutCluster;\n",
    "            #tokenRelativeFrequencyInCluster[token] = FInCluster;\n",
    "            #tokenRelativeFrequencyOutCluster[token] = FOutCluster;\n",
    "            tokenImportanceIndexInCluster[token] = importanceIndex;\n",
    "\n",
    "        #tokenRelativeFrequencyInClusters.append(tokenRelativeFrequencyInCluster);\n",
    "        #tokenRelativeFrequencyOutClusters.append(tokenRelativeFrequencyOutCluster);\n",
    "        tokenImportanceIndexInClusters.append(tokenImportanceIndexInCluster);\n",
    "\n",
    "    defaultNames = \"ABCDEFGHIJKLMNOPQRSTUWVXYZ\";\n",
    "    defaultNamesLength = len(defaultNames);\n",
    "\n",
    "    clusterKeywords = [];\n",
    "    minClusterSize = min([len(cluster) for cluster in clusters]);\n",
    "    maxClusterSize = max([len(cluster) for cluster in clusters]);\n",
    "    clusterNames = [];\n",
    "    for clusterIndex in range(len(clusters)):\n",
    "        cluster = clusters[clusterIndex];\n",
    "        clusterSize = len(cluster);\n",
    "        keywords = [v[0] for v in sorted(tokenImportanceIndexInClusters[clusterIndex].items(),key=operator.itemgetter(1),reverse=True)];\n",
    "        if(maxClusterSize>minClusterSize):\n",
    "            m = (maxKeywordsPerCluster-minKeywordsPerCluster)/float(maxClusterSize-minClusterSize);\n",
    "        else:\n",
    "            m=0;\n",
    "        keywordsCount = round(m*(clusterSize-minClusterSize)+minKeywordsPerCluster);\n",
    "        currentKeywords = [];\n",
    "        while(len(currentKeywords)<keywordsCount and len(keywords)>len(currentKeywords)):\n",
    "            currentKeywords = keywords[0:keywordsCount];\n",
    "            jointKeywords = \".\"+\".\".join(currentKeywords)+\".\";\n",
    "            toRemoveKeywords = [];\n",
    "            for keyword in currentKeywords:\n",
    "                if(jointKeywords.find(\" %s.\"%keyword)>=0):\n",
    "                    toRemoveKeywords.append(keyword);\n",
    "                elif(jointKeywords.find(\".%s \"%keyword)>=0):\n",
    "                    toRemoveKeywords.append(keyword);\n",
    "            for toRemoveKeyword in toRemoveKeywords:\n",
    "                keywords.remove(toRemoveKeyword);\n",
    "                currentKeywords.remove(toRemoveKeyword);\n",
    "        clusterKeywords.append(currentKeywords);\n",
    "        #print(currentKeywords);\n",
    "        clusterName = \"\";\n",
    "        if(clusterIndex<defaultNamesLength):\n",
    "            clusterName += defaultNames[clusterIndex];\n",
    "        else:\n",
    "            clusterName += \"{%d}\"%(clusterIndex);\n",
    "        clusterName += \" - \"+\", \".join(currentKeywords);\n",
    "        if(len(clusterName)>maxClusterNameLength):\n",
    "            clusterName = clusterName[0:maxClusterNameLength-1]+\"...\";\n",
    "        for vertexIndex in cluster:\n",
    "            network.vs[vertexIndex][\"Cluster Name\"] = clusterName;\n",
    "            network.vs[vertexIndex][\"Cluster Index\"] = clusterIndex;\n",
    "        clusterNames.append(clusterName);\n",
    "        print(clusterName);\n",
    "\n",
    "\n",
    "    # Saving the network\n",
    "    if(verboseMode): print(\"Saving the network.\");\n",
    "    # network.vs[\"kcore\"] = network.coreness()\n",
    "\n",
    "    xn.igraph2xnet(network,fileName=PJ('',\"%s_infomap.xnet\"%(jsonFileprefix)),ignoredNodeAtts=[\"Text\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
